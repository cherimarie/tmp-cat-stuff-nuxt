Background:
Search engine optimization (SEO) is designed to increase organic traffic to websites by increasing the accuracy of search engine results. Search engines, such as Google, Bing, DuckDuckGo utilize automated "crawlers" that scan and index information from websites and match that information to related search queries. Crawlers depend largely on scanning heading tags (e.g. H1 - H6) to build an outline of a site's content, and are sophisticated enough to account for intentional manipulation (e.g hidden tags, ghost pages).

Implementation:
This website is a relatively simple proof-of-concept and vehicle for programming concepts such as front-end frameworks, build tools, and APIs. Consequently, SEO can be almost exclusively based on the heading tags present on each view page. Additionally, this information can be made even more robust and descriptive by leveraging the head method and metadata on each page.
